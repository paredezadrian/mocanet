#!/usr/bin/env python3
"""Test script to verify model quality and compare checkpoints."""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

import torch
import torch.nn.functional as F
from src.mocanet.model import MOCANet
from src.mocanet.sst2_dataset import SST2Dataset
from src.mocanet.utils import load_checkpoint, get_device
from src.mocanet.config import Config


def test_checkpoint_quality(checkpoint_path: str, config_path: str = "configs/text_cls.yaml"):
    """Test the quality of a specific checkpoint."""
    print(f"\n{'='*60}")
    print(f"Testing checkpoint: {os.path.basename(checkpoint_path)}")
    print(f"{'='*60}")
    
    try:
        # Load configuration
        from src.mocanet.utils import load_config
        config_dict = load_config(config_path)
        config = Config(**config_dict)
        
        # Load checkpoint
        checkpoint = load_checkpoint(checkpoint_path)
        checkpoint_config = checkpoint['config']
        
        print(f"Checkpoint step: {checkpoint.get('step', 'N/A')}")
        print(f"Best validation metric: {checkpoint.get('best_val_metric', 'N/A')}")
        
        # Create model
        model = MOCANet(
            config=checkpoint_config.model,
            vocab_size=checkpoint_config.data.vocab_size,
            num_classes=2,
        )
        
        # Load model weights
        model.load_state_dict(checkpoint['model_state_dict'])
        model.eval()
        
        # Load vocabulary
        train_dataset = SST2Dataset(
            split="train",
            max_length=config.data.sequence_length,
            build_vocab=True,
            min_freq=config.text_cls.min_freq,
            max_vocab_size=config.data.vocab_size,
        )
        vocab = train_dataset.vocab
        
        # Test sentences
        test_sentences = [
            "This movie was absolutely fantastic!",
            "The food was terrible and the service was worse.",
            "I love this amazing product!",
            "This is the worst experience ever.",
            "The weather is beautiful today.",
            "I'm feeling quite neutral about this.",
            "What a wonderful day!",
            "The customer service was disappointing.",
            "This exceeded all my expectations!",
            "I'm so excited about this opportunity!"
        ]
        
        print(f"\nTesting {len(test_sentences)} sentences...")
        print("-" * 60)
        
        correct_predictions = 0
        total_predictions = 0
        
        for i, sentence in enumerate(test_sentences, 1):
            # Tokenize
            tokens = sentence.lower().split()
            token_ids = []
            for token in tokens:
                if token in vocab:
                    token_ids.append(vocab[token])
                else:
                    token_ids.append(vocab.get('<unk>', 1))
            
            # Pad to sequence length
            max_len = config.data.sequence_length
            if len(token_ids) < max_len:
                token_ids.extend([0] * (max_len - len(token_ids)))
            else:
                token_ids = token_ids[:max_len]
            
            # Convert to tensor
            input_ids = torch.tensor([token_ids], dtype=torch.long)
            attention_mask = (input_ids != 0).long()
            
            # Get prediction
            with torch.no_grad():
                outputs = model(input_ids, attention_mask)
                logits = outputs['logits']
                probabilities = F.softmax(logits, dim=-1)
                
                predicted_class = torch.argmax(logits, dim=1).item()
                confidence = probabilities[0][predicted_class].item()
                
                # Determine expected sentiment (simple heuristic)
                positive_words = ['fantastic', 'love', 'amazing', 'beautiful', 'wonderful', 'exceeded', 'excited', 'opportunity']
                negative_words = ['terrible', 'worse', 'worst', 'disappointing']
                
                sentence_lower = sentence.lower()
                positive_count = sum(1 for word in positive_words if word in sentence_lower)
                negative_count = sum(1 for word in negative_words if word in sentence_lower)
                
                if positive_count > negative_count:
                    expected_sentiment = "Positive"
                    expected_class = 1
                elif negative_count > positive_count:
                    expected_sentiment = "Negative"
                    expected_class = 0
                else:
                    expected_sentiment = "Neutral"
                    expected_class = -1
                
                # Check if prediction matches expectation
                if expected_class != -1:
                    if predicted_class == expected_class:
                        correct_predictions += 1
                        result = "‚úì"
                    else:
                        result = "‚úó"
                    total_predictions += 1
                else:
                    result = "?"
                
                sentiment = "Positive" if predicted_class == 1 else "Negative"
                
                print(f"{i:2d}. {result} {sentence[:50]:<50} | Pred: {sentiment} ({confidence:.3f}) | Exp: {expected_sentiment}")
        
        if total_predictions > 0:
            accuracy = correct_predictions / total_predictions
            print(f"\nAccuracy: {correct_predictions}/{total_predictions} = {accuracy:.1%}")
            
            if accuracy >= 0.8:
                print("üéâ Model quality: EXCELLENT")
            elif accuracy >= 0.6:
                print("üëç Model quality: GOOD")
            else:
                print("‚ö†Ô∏è  Model quality: POOR - needs more training")
        else:
            print("\nNo predictions could be evaluated")
            
    except Exception as e:
        print(f"‚ùå Error testing checkpoint: {e}")


def main():
    """Test both checkpoints."""
    print("MOCA-Net Model Quality Test")
    print("Comparing checkpoint quality...")
    
    # Test both checkpoints
    test_checkpoint_quality("runs/mocanet_best.pt")
    test_checkpoint_quality("runs/mocanet_final.pt")
    
    print(f"\n{'='*60}")
    print("RECOMMENDATION:")
    print("Use 'mocanet_final.pt' for interactive inference as it has")
    print("96.4% validation accuracy and is fully trained.")
    print(f"{'='*60}")


if __name__ == "__main__":
    main()
