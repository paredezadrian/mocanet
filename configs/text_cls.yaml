defaults:
  - base

# Override for text classification
model:
  embedding_dim: 256  # Larger embeddings for text
  num_experts: 6
  num_memory_slots: 32
  top_k_experts: 3
  num_memory_heads: 1

training:
  batch_size: 16  # Smaller batches for text
  max_steps: 2000
  learning_rate: 5e-5  # Lower learning rate for stability
  warmup_steps: 100

data:
  task: "text_classification"
  sequence_length: 128
  vocab_size: 10000
  num_classes: 2  # Binary classification (SST-2)

# Text classification specific
text_cls:
  dataset: "sst2"  # Full Stanford SST-2 dataset
  use_real_sst2: true  # Use real SST-2 from Hugging Face
  max_samples: 100000  # Increased for full dataset
  min_freq: 2  # Minimum token frequency
  pretrained_embeddings: false
